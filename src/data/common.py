"""Common code for scripts in src/data/ directory (remaining bits)"""
from pathlib import Path

from tqdm import tqdm

from src.utils.files import load_json_with_checks
from src.utils.git import GitRepo

# constants
ERROR_ARGS = 1
ERROR_OTHER = 2


def load_repositories_json(repositories_info_path: Path) -> dict:
    """Load <repositories.json> and convert into dict with project name as key

    The returned dict has the following structure:

    {
        '<project_name>': {  # e.g. "sqlalchemy"
            'project': <project_name>,  # e.g. "sqlalchemy"
            'repository_url': <repository_url>,  # e.g. "https://github.com/sqlalchemy/sqlalchemy.git"
            'repository_path': <repository_dir>,  # e.g. "/mnt/data/MSR_Challenge_2024/repositories/sqlalchemy"
        }, ...
    }

    :param Path repositories_info_path:  path to <repositories.json> file
    :return: data extracted from <repositories.json> file
    :rtype: dict
    """
    repo_clone_info = load_json_with_checks(repositories_info_path,
                                            file_descr="<repositories.json>",
                                            data_descr="info about cloned repos",
                                            err_code=ERROR_ARGS, expected_type=list)
    repo_clone_data = {
        repo_info['repository']: {
            key: value
            for key, value in repo_info.items()
        }
        for repo_info in repo_clone_info
    }

    return repo_clone_data


def reponame_to_repo_path(repo_clone_data, repo_name):
    """Return path where repository with given name was cloned into, or None

    NOTE: needs to be adjusted if the format of <repositories.json> file
    generated by download_repositories.py script changes.

    :param dict repo_clone_data: information about cloned repositories,
        result of load_repositories_json(Path('data/repositories_download_status.json'))
    :param str repo_name: full name of GitHub repository,
        which in the DevGPT dataset is stored in 'RepoName' field
    :return: path to cloned repository, if exists, otherwise None
    :rtype: Path or None
    """
    if repo_name not in repo_clone_data:
        return None

    return Path(repo_clone_data[repo_name]['repository_path'])


class DownloadedRepositories:
    """Helper class, to make it easier to operate on cloned repositories

    With object of this class, instanced with path to <repositories.json> file,
    you can easily create GitRepo objects based on 'RepoName' field from the
    DevGPT dataset.

    Example:
        >>> from src.data.common import DownloadedRepositories
        >>> from pathlib import Path
        >>> all_repos = DownloadedRepositories(Path('data/repositories_download_status.json'))
        >>> the_repo = all_repos.repo('sqlalchemy/sqlalchemy')
        >>> curr_diff = the_repo.unidiff('HEAD^^^^^')
    """
    def __init__(self, repositories_info_path: Path = Path('data/repositories_download_status.json')):
        """Create helper object, by providing it with path to <repositories.json>

        The `repositories_info_path` should point to JSON file with information
        about where one can find repositories cloned by the download_repositories.py
        script (the "clone_repos" stage in dvc.yaml).

        :param Path repositories_info_path: path to <repositories.json> file
        """
        self.repositories_info_path = repositories_info_path
        self.repo_clone_data = load_repositories_json(repositories_info_path)

    def repo(self, repo_name: str) -> GitRepo|None:
        """Create GitRepo object for cloned 'RepoName' project

        NOTE: currently does not handle gracefully case where project / repository
        could not be cloned for some reason, but is still present in the
        <repositories.json> file.

        :param str repo_name: full name of GitHub repository, present as
            'RepoName' field in DevGPT dataset
        :return: repository object to perform operations on
        :rtype: GitRepo or None
        """
        repo_path = reponame_to_repo_path(self.repo_clone_data, repo_name)
        if repo_path is not None:
            return GitRepo(repo_path)
        else:
            return None


def compute_chatgpt_sharings_stats(the_sharings):
    """Replace 'ChatgptSharing' field by its stats / summary

    This summary includes the following fields:

    - 'NumberOfChaptgptSharings'
    - 'TotalNumberOfPrompts'
    - 'TotalTokensOfPrompts'
    - 'TotalTokensOfAnswers'
    - 'NumberOfConversations'
    - 'Status404' - in how many cases 'Status' was 404 (Not Found)
    - 'ModelGPT4', 'ModelGPT3.5', 'ModelOther' - count the cases where
      'Model' field was 'GPT-4', was ''Default (GPT-3.5)', or had other
      value, respectively

    :param dict the_sharings: the 'Sources' part of sharing from DevGPT dataset,
        read from the JSON file; is *modified* by function
    :return: modified input
    :rtype: dict
    """
    for source in tqdm(the_sharings, desc="source ('ChatgptSharing')"):
        chatgpt_sharings_list = source['ChatgptSharing']
        del source['ChatgptSharing']

        source['NumberOfChatgptSharings'] = len(chatgpt_sharings_list)
        source['TotalNumberOfPrompts'] = 0
        source['TotalTokensOfPrompts'] = 0
        source['TotalTokensOfAnswers'] = 0
        source['NumberOfConversations'] = 0
        source['ModelGPT4'] = 0
        source['ModelGPT3.5'] = 0
        source['ModelOther'] = 0
        source['Status404'] = 0
        for chatgpt_sharing in chatgpt_sharings_list:
            # just in case value is null, or key is missing
            source['TotalNumberOfPrompts'] += chatgpt_sharing.get('NumberOfPrompts') or 0
            source['TotalTokensOfPrompts'] += chatgpt_sharing.get('TokensOfPrompts') or 0
            source['TotalTokensOfAnswers'] += chatgpt_sharing.get('TokensOfAnswers') or 0

            if 'Status' in chatgpt_sharing and chatgpt_sharing['Status'] == 404:
                source['Status404'] += 1

            if 'Model' in chatgpt_sharing:
                if chatgpt_sharing['Model'] == 'GPT-4':
                    source['ModelGPT4'] += 1
                elif chatgpt_sharing['Model'] == 'Default (GPT-3.5)':
                    source['ModelGPT3.5'] += 1
                else:
                    source['ModelOther'] += 1

            if 'Conversations' in chatgpt_sharing and chatgpt_sharing['Conversations'] is not None:
                conversations = chatgpt_sharing['Conversations']
                source['NumberOfConversations'] += len(conversations)

            # ...

    return the_sharings


def add_is_cloned_column(df_repo, repo_clone_data):
    """Compute and add 'is_cloned' column to `df_repo` dataframe

    :param pd.DataFrame df_repo: dataframe to modify, assumed to
        be indexed with 'RepoName'
    :param dict repo_clone_data: value returned by load_repositories_json()
        function from src.data.common module.
    :return: modified dataframe
    :rtype: pd.DataFrame
    """
    df_repo.loc[:, 'is_cloned'] = df_repo.index.map(
        lambda repo_name: bool(reponame_to_repo_path(repo_clone_data, repo_name)),
        na_action='ignore'
    )

    return df_repo
